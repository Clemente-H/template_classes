% ============================================================================
% SECCIÓN: INTRODUCCIÓN
% Entrenamiento de LLMs: Infraestructura y Tips
%============================================================================

\section{Introducción: Hardware vs Software}

\begin{frame}
  \frametitle{Hardware vs Software en el Entrenamiento de LLMs}

  Cuando pensamos en entrenar modelos de lenguaje, debemos diferenciar dos pilares fundamentales:

  \vspace{0.3cm}

  \begin{columns}[T]
    \begin{column}{.48\textwidth}
      \textbf{Hardware}
      \begin{itemize}
        \item GPUs y su VRAM
        \item Clusters de cómputo
        \item Interconexiones
        \item Costo en \$/hora
      \end{itemize}
    \end{column}

    \begin{column}{.48\textwidth}
      \textbf{Software}
      \begin{itemize}
        \item Bibliotecas de optimización
        \item Técnicas de eficiencia
        \item Frameworks de entrenamiento
        \item Estrategias de deployment
      \end{itemize}
    \end{column}
  \end{columns}

  \vspace{0.3cm}

  \begin{alertblock}{La interdependencia clave}
  No puedes entrenar sin hardware, pero el software determina la eficiencia y accesibilidad.
  \end{alertblock}
\end{frame}

\begin{frame}
  \frametitle{Software: Los 3 Pasos del Entrenamiento}

  Al entrenar un modelo en una GPU, hay tres pasos fundamentales que se repiten:

  \vspace{0.3cm}

  \begin{enumerate}
    \item \textbf{Forward Pass:} Los inputs pasan por el modelo para obtener sus outputs
    \item \textbf{Backward Pass:} Se calculan los gradientes (derivadas de la loss)
    \item \textbf{Optimization:} Se usan los gradientes para actualizar los parámetros
  \end{enumerate}

  \vspace{0.3cm}

  \begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{GenIA/training_3_steps.png}
    \caption{Diagrama de los 3 pasos del entrenamiento}
  \end{figure}

  \vspace{0.2cm}
  \small
  \textbf{Implicación:} Cada paso consume memoria de manera distinta. El backward y optimization son los más costosos.
\end{frame}

\begin{frame}
  \frametitle{¿Por qué es tan caro entrenar LLMs?}

  \begin{block}{El costo del entrenamiento}
    GPT-3 (175B parámetros) costó aproximadamente \alert{\$4.6 millones} en recursos computacionales (~355 GPU-years en V100).
  \end{block}

  \vspace{0.5cm}

  \textbf{Pero hay buenas noticias:}
  \begin{itemize}
    \item Pre-training desde cero = solo para grandes labs (OpenAI, Google, Meta)
    \item \alert{Fine-tuning con técnicas modernas = muy accesible}
    \item Con las técnicas que veremos hoy, puedes adaptar modelos grandes en hardware limitado
  \end{itemize}

  \vspace{0.3cm}

  \begin{alertblock}{Objetivo de la clase}
    Entender QUÉ recursos necesitamos y CÓMO optimizarlos para hacerlo accesible.
  \end{alertblock}
\end{frame}

\begin{frame}{Visión General de la Clase}
    Hoy nos interesa ver el ciclo completo desde tener un modelo hasta ponerlo en producción de manera eficiente.
    \vspace{0.5cm}
    \begin{enumerate}
        \item \textbf{Hardware y Recursos Computacionales:} GPUs, VRAM, cálculo de memoria necesaria
        \item \textbf{Técnicas de Optimización y Eficiencia:} Quantization, LoRA, QLoRA para entrenar con menos recursos
        \item \textbf{Deployment en Producción:} vLLM, TGI y estrategias para servir modelos eficientemente
    \end{enumerate}
\end{frame}
